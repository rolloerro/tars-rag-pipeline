from sentence_transformers import SentenceTransformer
import numpy as np
import faiss

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥-–º–æ–¥–µ–ª—å
model = SentenceTransformer('all-MiniLM-L6-v2')

# 2. –ù–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¥–µ–º–æ)
docs = [
    "ML Engineer designs models for real-world applications.",
    "RAG combines retrieval with generation to enhance LLM accuracy.",
    "Vector databases store embeddings for semantic search.",
]

# 3. –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
embeddings = model.encode(docs)
embeddings = np.array(embeddings).astype('float32')

# 4. –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é FAISS
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

# 5. –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
query = "How does RAG improve LLMs?"
query_emb = model.encode([query]).astype('float32')

# 6. –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
_, indices = index.search(query_emb, k=1)
print("üîç Best match:", docs[indices[0][0]])
